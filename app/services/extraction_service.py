"""Refactored service to use prompts from a YAML file for easier management and extensibility."""
import hashlib
import json
import logging
import time
import uuid
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_core.documents import Document
from sqlalchemy.orm import Session
import yaml

from app.providers.base import ProvedorExtracaoBase, ResultadoExtracao
from app.models.schemas import MetricasExtracao
from app.core.logging import obter_logger
from app.core.exceptions import ExtracaoException
from app.core.config import settings
from app.providers.docling_provider import DoclingProvider
try:
    from app.providers.azure_provider import AzureDocumentIntelligenceProvider
except ImportError:
    AzureDocumentIntelligenceProvider = None
from app.services.vector_service import VectorStoreService
from app.services.cost_service import CostTrackingService

logger = obter_logger(__name__)


@dataclass
class ResultadoExtracaoCompleto:
    """Resultado completo da extra√ß√£o de texto"""
    texto: str
    provedor_usado: str
    qualidade: float
    tempo_total: float
    metadados: Dict[str, Any]
    hash_arquivo: str


@dataclass
class ResultadoClassificacao:
    """Resultado da classifica√ß√£o de documento"""
    tipo_documento: str
    confianca: float
    metadados: Dict[str, Any]


@dataclass
class ResultadoExtracaoDados:
    """Resultado da extra√ß√£o de dados estruturados"""
    dados_extraidos: Dict[str, Any]
    confianca: float
    metadados: Dict[str, Any]


@dataclass
class ResultadoProcessamentoCompleto:
    """Resultado completo de todo o processamento"""
    documento_id: str
    hash_arquivo: str
    texto_extraido: str
    classificacao: ResultadoClassificacao
    dados_estruturados: ResultadoExtracaoDados
    tempo_total: float
    custos_totais: Dict[str, Any]
    metadados_completos: Dict[str, Any]


class ServicoExtracaoUnificado:
    """
    Servi√ßo unificado que gerencia todo o pipeline de processamento:
    1. Extra√ß√£o de texto dos documentos
    2. Classifica√ß√£o adaptativa com aprendizado
    3. Extra√ß√£o de dados estruturados
    """

    def __init__(self, vector_service: VectorStoreService, cost_service: CostTrackingService):
        """
        Inicializa o servi√ßo unificado

        Args:
            vector_service: Servi√ßo de banco vetorial
            cost_service: Servi√ßo de rastreamento de custos
        """
        self.vector_service = vector_service
        self.cost_service = cost_service

        # Log expl√≠cito da chave OpenAI usada
        try:
            openai_key = settings.llm.openai_api_key.get_secret_value()
        except Exception as e:
            openai_key = f"(erro ao obter chave: {e})"
        logger.info(f"[ETL] Chave OpenAI para classifica√ß√£o: {openai_key}")
        logger.info(f"[ETL] Chave OpenAI para extra√ß√£o: {openai_key}")

        # Provedores de extra√ß√£o de texto
        self.provedores: List[ProvedorExtracaoBase] = []
        self._inicializar_provedores()

        # LLMs para classifica√ß√£o e extra√ß√£o
        self.llm_classificacao = ChatOpenAI(
            model=settings.llm.classification_model,
            api_key=openai_key,
            temperature=0
        )

        self.llm_extracao = ChatOpenAI(
            model=settings.llm.extraction_model,
            api_key=openai_key,
            temperature=0
        )

        # Parsers
        self.str_parser = StrOutputParser()
        self.json_parser = JsonOutputParser()

        # Schemas de extra√ß√£o
        self.extraction_schemas = self._load_extraction_schemas()

        # Criar prompts
        self._create_prompts()

        logger.info("Servi√ßo de extra√ß√£o unificado inicializado")

    def _inicializar_provedores(self):
        """Inicializa os provedores de extra√ß√£o de texto"""
        # Docling √© sempre o primeiro (padr√£o)
        self.provedores.append(DoclingProvider())

        # Azure como fallback se configurado
        if settings.azure_endpoint and settings.azure_key:
            if AzureDocumentIntelligenceProvider:
                self.provedores.append(AzureDocumentIntelligenceProvider(
                    endpoint=settings.azure_endpoint,
                    api_key=settings.azure_key
                ))
                logger.info("Provedor Azure configurado como fallback")

        logger.info(
            f"Provedores inicializados: {[p.nome for p in self.provedores]}")

    def _load_extraction_schemas(self) -> Dict[str, Dict[str, Any]]:
        """Carrega schemas de extra√ß√£o para cada tipo de documento"""
        return {
            "CNH": {
                "nome_completo": "string - Nome completo do portador",
                "numero_registro": "string - N√∫mero do registro da CNH",
                "cpf": "string - CPF do portador",
                "data_nascimento": "string - Data de nascimento (DD/MM/AAAA)",
                "categoria": "string - Categoria da habilita√ß√£o (A, B, C, D, E)",
                "data_primeira_habilitacao": "string - Data da primeira habilita√ß√£o",
                "data_validade": "string - Data de validade da CNH",
                "orgao_expedidor": "string - √ìrg√£o que expediu a CNH",
                "numero_espelho": "string - N√∫mero do espelho/seguran√ßa"
            },
            "Comprovante Banc√°rio": {
                "banco": "string - Nome do banco",
                "agencia": "string - N√∫mero da ag√™ncia",
                "conta": "string - N√∫mero da conta",
                "tipo_operacao": "string - Tipo da opera√ß√£o (transfer√™ncia, dep√≥sito, etc.)",
                "valor": "string - Valor da opera√ß√£o",
                "data_operacao": "string - Data da opera√ß√£o",
                "codigo_autenticacao": "string - C√≥digo de autentica√ß√£o",
                "favorecido": "string - Nome do favorecido/destinat√°rio",
                "documento_favorecido": "string - CPF/CNPJ do favorecido"
            },
            "Cart√£o CNPJ": {
                "cnpj": "string - N√∫mero do CNPJ",
                "razao_social": "string - Raz√£o social da empresa",
                "nome_fantasia": "string - Nome fantasia",
                "data_abertura": "string - Data de abertura da empresa",
                "cnae_principal": "string - C√≥digo CNAE principal",
                "natureza_juridica": "string - Natureza jur√≠dica",
                "endereco_completo": "string - Endere√ßo completo",
                "situacao_cadastral": "string - Situa√ß√£o cadastral atual",
                "data_situacao": "string - Data da situa√ß√£o cadastral"
            },
            "CEI da Obra": {
                "numero_cei": "string - N√∫mero da matr√≠cula CEI",
                "endereco_obra": "string - Endere√ßo completo da obra",
                "proprietario_nome": "string - Nome do propriet√°rio",
                "proprietario_documento": "string - CPF/CNPJ do propriet√°rio",
                "responsavel_tecnico": "string - Nome do respons√°vel t√©cnico",
                "numero_art": "string - N√∫mero da ART",
                "data_inicio": "string - Data de in√≠cio da obra",
                "tipo_obra": "string - Tipo da obra"
            },
            "Inscri√ß√£o Municipal": {
                "numero_inscricao": "string - N√∫mero da inscri√ß√£o municipal",
                "razao_social": "string - Raz√£o social",
                "nome_fantasia": "string - Nome fantasia",
                "cnpj": "string - CNPJ da empresa",
                "endereco": "string - Endere√ßo do estabelecimento",
                "atividade_principal": "string - Atividade econ√¥mica principal",
                "data_inscricao": "string - Data da inscri√ß√£o",
                "situacao": "string - Situa√ß√£o da inscri√ß√£o"
            },
            "Termo de Responsabilidade": {
                "responsavel_nome": "string - Nome do respons√°vel",
                "responsavel_documento": "string - CPF/CNPJ do respons√°vel",
                "objeto_responsabilidade": "string - Objeto da responsabilidade",
                "descricao_obrigacoes": "string - Descri√ß√£o das obriga√ß√µes",
                "prazo_validade": "string - Prazo de validade",
                "data_assinatura": "string - Data da assinatura",
                "testemunhas": "array - Nomes das testemunhas"
            },
            "Alvar√° Municipal": {
                "numero_alvara": "string - N√∫mero do alvar√°",
                "razao_social": "string - Raz√£o social da empresa",
                "cnpj": "string - CNPJ",
                "endereco": "string - Endere√ßo do estabelecimento",
                "atividades_permitidas": "array - Lista de atividades permitidas",
                "data_emissao": "string - Data de emiss√£o",
                "data_validade": "string - Data de validade",
                "orgao_emissor": "string - √ìrg√£o emissor"
            },
            "Contrato Social": {
                "razao_social": "string - Raz√£o social da empresa",
                "nome_fantasia": "string - Nome fantasia",
                "cnpj": "string - CNPJ (se for altera√ß√£o)",
                "objeto_social": "string - Objeto social",
                "capital_social": "string - Valor do capital social",
                "endereco_sede": "string - Endere√ßo da sede",
                "socios": "array - Lista de s√≥cios com participa√ß√£o",
                "administradores": "array - Lista de administradores",
                "data_constituicao": "string - Data de constitui√ß√£o"
            },
            "Fatura Telef√¥nica": {
                "operadora": "string - Nome da operadora",
                "numero_linha": "string - N√∫mero da linha",
                "periodo_referencia": "string - Per√≠odo de refer√™ncia",
                "valor_total": "string - Valor total da fatura",
                "data_vencimento": "string - Data de vencimento",
                "consumo_dados": "string - Consumo de dados",
                "chamadas_locais": "string - Quantidade/valor de chamadas locais",
                "servicos_adicionais": "array - Servi√ßos adicionais cobrados"
            },
            "Nota Fiscal de Servi√ßos Eletr√¥nica": {
                "numero_nota": "string - N√∫mero da nota fiscal",
                "prestador_nome": "string - Nome do prestador",
                "prestador_cnpj": "string - CNPJ do prestador",
                "tomador_nome": "string - Nome do tomador",
                "tomador_documento": "string - CPF/CNPJ do tomador",
                "descricao_servicos": "string - Descri√ß√£o dos servi√ßos",
                "valor_servicos": "string - Valor dos servi√ßos",
                "iss": "string - Valor do ISS",
                "valor_total": "string - Valor total da nota",
                "data_emissao": "string - Data de emiss√£o"
            }
        }

    def _get_prompt_for_document_type(self, tipo_documento: str) -> Optional[str]:
        """Carrega prompt espec√≠fico do YAML para o tipo de documento"""
        try:
            import yaml
            import os

            prompts_file = os.path.join(os.path.dirname(
                __file__), '../../config/prompts.yaml')

            with open(prompts_file, 'r', encoding='utf-8') as f:
                prompts_data = yaml.safe_load(f)

            # Normalizar nome do tipo para garantir correspond√™ncia
            def normaliza(s):
                return s.strip().lower()

            tipos_yaml = prompts_data.get('extracao', {}).get('tipos', {})
            tipos_disponiveis = list(tipos_yaml.keys())
            tipo_normalizado = normaliza(tipo_documento)
            for tipo_yaml in tipos_disponiveis:
                if normaliza(tipo_yaml) == tipo_normalizado:
                    return tipos_yaml[tipo_yaml].get('prompt')

            logger.warning(
                f"Prompt n√£o encontrado para tipo: {tipo_documento}. Tipos dispon√≠veis: {tipos_disponiveis}")
            return None

        except Exception as e:
            logger.error(f"Erro ao carregar prompt do YAML: {e}")
            return None

    def _create_prompts(self):
        """Criar prompts - LLMs j√° foram inicializados no __init__"""
        # Os LLMs j√° foram criados no __init__ com a chave correta
        # N√£o precisamos recriar aqui para evitar problemas de chave
        logger.info("Prompts configurados - LLMs j√° inicializados no __init__")

    def _calcular_hash_arquivo(self, conteudo: bytes) -> str:
        """Calcula hash SHA-256 do arquivo"""
        return hashlib.sha256(conteudo).hexdigest()

    def _provedor_suporta_formato(self, provedor: ProvedorExtracaoBase, extensao: str) -> bool:
        """Verifica se provedor suporta o formato"""
        return extensao.lower() in [fmt.lower() for fmt in provedor.suporta_formatos]

    async def processar_documento_completo(
        self,
        conteudo_arquivo: bytes,
        extensao: str,
        nome_arquivo: str = None,
        db_session: Optional[Session] = None
    ) -> ResultadoProcessamentoCompleto:
        """
        Processa documento completo: extra√ß√£o, classifica√ß√£o e extra√ß√£o de dados

        Args:
            conteudo_arquivo: Conte√∫do bin√°rio do arquivo
            extensao: Extens√£o do arquivo
            nome_arquivo: Nome do arquivo
            db_session: Sess√£o do banco de dados

        Returns:
            Resultado completo do processamento
        """
        document_id = str(uuid.uuid4())
        inicio_processamento = time.time()

        logger.info(
            f"Iniciando processamento completo do documento {document_id}")

        try:
            # 1. Extra√ß√£o de texto
            resultado_texto = await self.extrair_texto(
                conteudo_arquivo, extensao, nome_arquivo
            )
            logger.info(
                f"Texto extra√≠do com qualidade {resultado_texto.qualidade:.2f}")

            # 2. Classifica√ß√£o do documento
            resultado_classificacao = await self.classificar_documento(
                resultado_texto.texto, document_id, db_session
            )
            logger.info(
                f"Documento classificado como '{resultado_classificacao.tipo_documento}' com confian√ßa {resultado_classificacao.confianca:.2f}")

            # 3. Extra√ß√£o de dados estruturados
            resultado_dados = await self.extrair_dados_estruturados(
                resultado_texto.texto,
                resultado_classificacao.tipo_documento,
                document_id,
                db_session
            )
            logger.info(
                f"Dados estruturados extra√≠dos: {len(resultado_dados.dados_extraidos)} campos")

            # 4. Salvar no banco vetorial para aprendizado futuro
            await self._salvar_no_banco_vetorial(
                resultado_texto.texto,
                resultado_classificacao.tipo_documento,
                resultado_dados.dados_extraidos,
                resultado_classificacao.confianca,
                db_session
            )

            # 5. Calcular custos totais
            custos_totais = self._calcular_custos_totais([
                resultado_classificacao.metadados,
                resultado_dados.metadados
            ])

            tempo_total = time.time() - inicio_processamento

            # 6. Montar resultado completo
            resultado_completo = ResultadoProcessamentoCompleto(
                documento_id=document_id,
                hash_arquivo=resultado_texto.hash_arquivo,
                texto_extraido=resultado_texto.texto,
                classificacao=resultado_classificacao,
                dados_estruturados=resultado_dados,
                tempo_total=tempo_total,
                custos_totais=custos_totais,
                metadados_completos={
                    "extracao_texto": resultado_texto.metadados,
                    "classificacao": resultado_classificacao.metadados,
                    "extracao_dados": resultado_dados.metadados,
                    "arquivo_original": {
                        "nome": nome_arquivo,
                        "extensao": extensao,
                        "tamanho_bytes": len(conteudo_arquivo),
                        "hash": resultado_texto.hash_arquivo
                    }
                }
            )

            logger.info(
                f"Processamento completo finalizado em {tempo_total:.2f}s")
            return resultado_completo

        except Exception as e:
            tempo_total = time.time() - inicio_processamento
            error_msg = f"Erro no processamento completo: {str(e)}"
            logger.error(error_msg, exc_info=True)
            raise ExtracaoException(
                error_msg,
                details={
                    "document_id": document_id,
                    "processing_time": tempo_total,
                    "stage": "processamento_completo"
                },
                error_code="PROCESSAMENTO_COMPLETO_FALHOU"
            )

    async def extrair_texto(
        self,
        conteudo_arquivo: bytes,
        extensao: str,
        nome_arquivo: str = None
    ) -> ResultadoExtracaoCompleto:
        """
        Extrai texto do documento usando estrat√©gia de fallback
        """
        hash_arquivo = self._calcular_hash_arquivo(conteudo_arquivo)
        logger.info(
            f"Iniciando extra√ß√£o para arquivo {nome_arquivo or 'desconhecido'} "
            f"({extensao}, {len(conteudo_arquivo)} bytes, hash: {hash_arquivo[:8]}...)"
        )

        melhor_resultado: Optional[ResultadoExtracao] = None
        provedores_usados = []

        for provedor in self.provedores:
            if not self._provedor_suporta_formato(provedor, extensao):
                logger.debug(
                    f"Provedor {provedor.nome} n√£o suporta formato {extensao}")
                continue

            try:
                logger.info(f"Tentando extra√ß√£o com {provedor.nome}")
                resultado = await provedor.extrair_texto(
                    conteudo_arquivo, extensao, nome_arquivo
                )

                provedores_usados.append({
                    "provedor": provedor.nome,
                    "sucesso": resultado.sucesso,
                    "qualidade": resultado.metricas.qualidade_score,
                    "caracteres": resultado.metricas.caracteres_extraidos,
                    "tempo": resultado.metricas.tempo_processamento
                })

                if resultado.sucesso:
                    # Se √© o primeiro resultado ou √© melhor que o anterior
                    if (melhor_resultado is None or
                            resultado.metricas.qualidade_score > melhor_resultado.metricas.qualidade_score):
                        melhor_resultado = resultado

                    # Se qualidade √© boa o suficiente, usar este resultado
                    if resultado.metricas.qualidade_score >= settings.quality.qualidade_minima_extracao:
                        logger.info(
                            f"Qualidade suficiente alcan√ßada com {provedor.nome}: "
                            f"{resultado.metricas.qualidade_score:.2f}"
                        )
                        break
                else:
                    logger.warning(
                        f"Falha na extra√ß√£o com {provedor.nome}: {resultado.erro}")

            except Exception as e:
                logger.error(
                    f"Erro inesperado com provedor {provedor.nome}: {e}")
                provedores_usados.append({
                    "provedor": provedor.nome,
                    "sucesso": False,
                    "erro": str(e)
                })

        if melhor_resultado is None or not melhor_resultado.sucesso:
            raise ExtracaoException(
                "Nenhum provedor conseguiu extrair texto do documento",
                details={
                    "extensao": extensao,
                    "tamanho_bytes": len(conteudo_arquivo),
                    "provedores_tentados": provedores_usados
                },
                error_code="EXTRACAO_FALHOU"
            )

        return ResultadoExtracaoCompleto(
            texto=melhor_resultado.texto,
            provedor_usado=melhor_resultado.metricas.metodo_extracao,
            qualidade=melhor_resultado.metricas.qualidade_score,
            tempo_total=sum(p.get("tempo", 0)
                            for p in provedores_usados if p.get("tempo")),
            metadados={
                "provedores_usados": provedores_usados,
                "metadata_extracao": melhor_resultado.metadata or {},
                "metricas": melhor_resultado.metricas.dict()
            },
            hash_arquivo=hash_arquivo
        )

    async def classificar_documento(
        self,
        texto_documento: str,
        document_id: Optional[str] = None,
        db_session: Optional[Session] = None
    ) -> ResultadoClassificacao:
        """
        Classifica documento usando aprendizado adaptativo
        """
        import os
        logger.info(
            f"[DEBUG][classificar_documento] id(settings): {id(settings)}")
        logger.info(
            f"[DEBUG][classificar_documento] settings.llm.openai_api_key: {getattr(settings.llm.openai_api_key, 'get_secret_value', lambda: 'N/A')()}")
        logger.info(
            f"[DEBUG][classificar_documento] os.environ['OPENAI_API_KEY']: {os.environ.get('OPENAI_API_KEY', 'N/A')}")
        logger.info(f"[DEBUG][classificar_documento] CWD: {os.getcwd()}")

        call_id = str(uuid.uuid4())[:8]
        start_time = time.time()

        try:
            logger.info(
                f"Iniciando classifica√ß√£o adaptativa - Call ID: {call_id}")

            # Estrat√©gia para documentos extensos
            if len(texto_documento) > 5000:
                text_length = len(texto_documento)
                start_text = texto_documento[:800]
                middle_text = texto_documento[text_length //
                                              2-400:text_length//2+400]
                end_text = texto_documento[-800:]
                truncated_text = f"{start_text}\n...\n{middle_text}\n...\n{end_text}"
                logger.info(
                    "Documento extenso: usando estrat√©gia de amostragem")
            else:
                truncated_text = texto_documento[:2000]

            # Buscar documentos similares
            similar_docs = self.vector_service.get_similar_documents_for_classification(
                truncated_text, k=3
            )

            # Escolher abordagem
            if similar_docs and len(similar_docs) > 0:
                logger.info(
                    f"Usando classifica√ß√£o adaptativa com {len(similar_docs)} exemplos")
                examples = self._format_classification_examples(similar_docs)

                classification_result = self.classification_adaptive_chain.invoke({
                    "document_text": truncated_text,
                    "examples": examples
                })

                confianca = self._calculate_adaptive_confidence(similar_docs)
            else:
                logger.info("Usando classifica√ß√£o base (sem exemplos)")
                classification_result = self.classification_base_chain.invoke({
                    "document_text": truncated_text
                })
                confianca = 0.7

            # Processar resultado
            tipo_documento = classification_result.strip()
            tipo_documento = self._validate_and_fix_type(tipo_documento)

            # Calcular m√©tricas
            elapsed_time = time.time() - start_time
            estimated_input_tokens = len(truncated_text) // 4
            estimated_output_tokens = len(classification_result) // 4

            # Rastrear custos
            if self.cost_service:
                self.cost_service.record_llm_usage(
                    call_id=call_id,
                    model=settings.llm.classification_model,
                    operation="classification",
                    input_tokens=estimated_input_tokens,
                    output_tokens=estimated_output_tokens,
                    success=True,
                    processing_time=elapsed_time,
                    document_id=document_id,
                    db_session=db_session
                )

            metadados = {
                "call_id": call_id,
                "model_used": settings.llm.classification_model,
                "processing_time": elapsed_time,
                "examples_used": len(similar_docs) if similar_docs else 0,
                "approach": "adaptive" if similar_docs else "base",
                "input_tokens": estimated_input_tokens,
                "output_tokens": estimated_output_tokens
            }

            logger.info(
                f"Documento classificado como '{tipo_documento}' com confian√ßa {confianca:.3f}")

            return ResultadoClassificacao(
                tipo_documento=tipo_documento,
                confianca=confianca,
                metadados=metadados
            )

        except Exception as e:
            elapsed_time = time.time() - start_time
            error_msg = f"Erro na classifica√ß√£o: {str(e)}"
            logger.error(error_msg, exc_info=True)

            if self.cost_service:
                self.cost_service.record_llm_usage(
                    call_id=call_id,
                    model=settings.llm.classification_model,
                    operation="classification",
                    input_tokens=0,
                    output_tokens=0,
                    success=False,
                    processing_time=elapsed_time,
                    error=error_msg,
                    document_id=document_id,
                    db_session=db_session
                )

            raise RuntimeError(f"Falha na classifica√ß√£o: {str(e)}")

    async def extrair_dados_estruturados(
        self,
        texto_documento: str,
        tipo_documento: str,
        document_id: Optional[str] = None,
        db_session: Optional[Session] = None
    ) -> ResultadoExtracaoDados:
        """
        Extrai dados estruturados usando aprendizado adaptativo
        """
        import os
        logger.info(
            f"[DEBUG][extrair_dados_estruturados] id(settings): {id(settings)}")
        logger.info(
            f"[DEBUG][extrair_dados_estruturados] settings.llm.openai_api_key: {getattr(settings.llm.openai_api_key, 'get_secret_value', lambda: 'N/A')()}")
        logger.info(
            f"[DEBUG][extrair_dados_estruturados] os.environ['OPENAI_API_KEY']: {os.environ.get('OPENAI_API_KEY', 'N/A')}")
        logger.info(f"[DEBUG][extrair_dados_estruturados] CWD: {os.getcwd()}")

        from datetime import datetime
        call_id = str(uuid.uuid4())[:8]
        start_time = time.time()

        try:
            logger.info(
                f"Iniciando extra√ß√£o adaptativa para {tipo_documento} - Call ID: {call_id}")

            # Verificar schema
            if tipo_documento not in self.extraction_schemas:
                raise ValueError(
                    f"Schema n√£o encontrado para tipo: {tipo_documento}")

            schema = self.extraction_schemas[tipo_documento]
            schema_text = self._format_schema(schema)

            # Estrat√©gia para documentos extensos
            if len(texto_documento) > 8000:
                # Para documentos muito extensos, usar chunking inteligente
                from app.services.document_chunking_service import IntelligentChunkingService

                chunking_service = IntelligentChunkingService(
                    max_chunk_size=3000)
                chunks = chunking_service.chunk_document(
                    texto_documento, tipo_documento)

                logger.info(
                    f"Processando documento extenso em {len(chunks)} chunks")

                # Processar cada chunk
                chunk_results = []
                for chunk in chunks:
                    chunk_data = await self._extract_from_chunk(chunk, tipo_documento, schema_text)
                    chunk_results.append((chunk, chunk_data))

                # Consolidar resultados
                dados_extraidos = self._consolidate_chunk_results(
                    chunk_results, schema)
                confianca = self._calculate_chunked_confidence(chunk_results)

                elapsed_time = time.time() - start_time

                metadados = {
                    "call_id": call_id,
                    "model_used": settings.llm.extraction_model,
                    "processing_time": elapsed_time,
                    "approach": "chunked",
                    "total_chunks": len(chunks),
                    "fields_extracted": len(dados_extraidos)
                }

                return ResultadoExtracaoDados(
                    dados_extraidos=dados_extraidos,
                    confianca=confianca,
                    metadados=metadados
                )
            else:
                # Truncar normalmente
                truncated_text = texto_documento[:3000]

            # Buscar exemplos similares
            similar_docs = self.vector_service.get_similar_documents_for_extraction(
                truncated_text, tipo_documento, k=3
            )

            # Usar APENAS prompt espec√≠fico do YAML
                logger.info(
                f"üéØ Usando prompt ESPEC√çFICO do YAML para {tipo_documento}")

            # Carregar prompt espec√≠fico do YAML
            prompt_especifico = self._get_prompt_for_document_type(
                tipo_documento)

            if not prompt_especifico:
                raise ValueError(
                    f"Prompt espec√≠fico n√£o encontrado para tipo: {tipo_documento}")

            if not self.llm_extracao:
                raise ValueError("LLM de extra√ß√£o n√£o inicializado")

            # Substituir placeholder pelo texto do documento
            prompt_formatado = prompt_especifico.replace(
                "DOCUMENT_TEXT_PLACEHOLDER", truncated_text)

            # Usar LLM diretamente com o prompt espec√≠fico
            from langchain_core.messages import HumanMessage
            response = await self.llm_extracao.ainvoke([HumanMessage(content=prompt_formatado)])

            # Capturar a resposta completa da LLM
            resposta_completa_llm = response.content
            logger.info(
                f"üéØ Resposta completa da LLM capturada: {len(resposta_completa_llm)} caracteres")

            # Fazer parse do JSON para valida√ß√£o
            try:
                dados_extraidos_parsed = json.loads(resposta_completa_llm)
                # Se o parse foi bem-sucedido, usar a resposta completa como dados extra√≠dos
                dados_extraidos = dados_extraidos_parsed
                confianca = 0.85  # Alta confian√ßa para prompts espec√≠ficos do YAML
                status_extracao = "extraido_com_sucesso"
            except json.JSONDecodeError:
                # Se n√£o conseguir fazer parse, ainda assim retornar a resposta completa
                dados_extraidos = {
                    "resposta_completa_llm": resposta_completa_llm,
                    "tipo_documento": tipo_documento,
                    "texto_analisado": len(truncated_text),
                    "timestamp_extracao": datetime.utcnow().isoformat(),
                    "status": "resposta_nao_json_mas_completa"
                }
                confianca = 0.7
                status_extracao = "resposta_completa_capturada"

            logger.info(
                f"‚úÖ Extra√ß√£o QUALIFICADA bem-sucedida: {len(str(dados_extraidos))} caracteres de resposta")
            logger.debug(f"Dados extra√≠dos: {dados_extraidos}")

            # Calcular m√©tricas
            elapsed_time = time.time() - start_time
            estimated_input_tokens = len(truncated_text + schema_text) // 4
            estimated_output_tokens = len(resposta_completa_llm) // 4

            # Rastrear custos
            if self.cost_service:
                self.cost_service.record_llm_usage(
                    call_id=call_id,
                    model=settings.llm.extraction_model,
                    operation="extraction",
                    input_tokens=estimated_input_tokens,
                    output_tokens=estimated_output_tokens,
                    success=True,
                    processing_time=elapsed_time,
                    document_id=document_id,
                    db_session=db_session
                )

            metadados = {
                "call_id": call_id,
                "model_used": settings.llm.extraction_model,
                "processing_time": elapsed_time,
                "examples_used": len(similar_docs) if similar_docs else 0,
                "approach": "adaptive" if similar_docs else "base",
                "fields_extracted": len(dados_extraidos),
                "input_tokens": estimated_input_tokens,
                "output_tokens": estimated_output_tokens
            }

            logger.info(
                f"Dados estruturados extra√≠dos: {len(dados_extraidos)} campos")

            return ResultadoExtracaoDados(
                dados_extraidos=dados_extraidos,
                confianca=confianca,
                metadados=metadados
            )

        except json.JSONDecodeError as e:
            elapsed_time = time.time() - start_time
            error_msg = f"Erro ao fazer parse do JSON da resposta: {e}"
            logger.error(error_msg)
            logger.debug(
                f"Resposta da LLM: {response.content if 'response' in locals() else 'N/A'}")

            # Retornar dados b√°sicos como fallback
            from datetime import datetime
            dados_basicos = {
                "tipo_documento": tipo_documento,
                "texto_analisado": len(truncated_text),
                "timestamp_extracao": datetime.utcnow().isoformat(),
                "status": "erro_parse_json",
                "erro_detalhado": str(e)
            }

            return ResultadoExtracaoDados(
                dados_extraidos=dados_basicos,
                confianca=0.2,
                metadados={
                    "call_id": call_id,
                    "processing_time": elapsed_time,
                    "erro": error_msg,
                    "approach": "fallback_basico"
                }
            )

        except Exception as e:
            elapsed_time = time.time() - start_time
            error_msg = f"Erro na extra√ß√£o qualificada: {str(e)}"
            logger.error(error_msg)

            # Retornar dados b√°sicos como fallback
            from datetime import datetime
            dados_basicos = {
                "tipo_documento": tipo_documento,
                "texto_analisado": len(texto_documento),
                "timestamp_extracao": datetime.utcnow().isoformat(),
                "status": "extraido_com_fallback",
                "erro_extracao_completa": str(e)
            }

            return ResultadoExtracaoDados(
                dados_extraidos=dados_basicos,
                confianca=0.3,
                metadados={
                    "call_id": call_id,
                    "processing_time": elapsed_time,
                    "erro": error_msg,
                    "approach": "fallback_basico"
                }
            )

    def _format_schema(self, schema: Dict[str, str]) -> str:
        """Formata schema para o prompt"""
        return "\n".join([f"- {field}: {desc}" for field, desc in schema.items()])

    def _format_classification_examples(self, similar_docs: list) -> str:
        """Formata exemplos para classifica√ß√£o"""
        examples = []
        for doc in similar_docs:
            examples.append(
                f"Texto: {doc['text'][:200]}...\nTipo: {doc['document_type']}")
        return "\n\n".join(examples)

    def _format_extraction_examples(self, similar_docs: list) -> str:
        """Formata exemplos para extra√ß√£o"""
        examples = []
        for doc in similar_docs:
            examples.append(
                f"Documento: {doc['text'][:200]}...\nDados: {doc['extracted_data']}")
        return "\n\n".join(examples)

    def _validate_and_fix_type(self, tipo_documento: str) -> str:
        """Valida e corrige tipo de documento"""
        tipos_validos = settings.DOCUMENT_TYPES
        if tipo_documento in tipos_validos:
            return tipo_documento

        # Tentar encontrar tipo similar
        for tipo in tipos_validos:
            if tipo.lower() in tipo_documento.lower():
                return tipo

        return "Documento N√£o Classificado"

    def _validate_extracted_data(self, dados: Dict[str, Any], schema: Dict[str, str]) -> Dict[str, Any]:
        """Valida dados extra√≠dos"""
        if not isinstance(dados, dict):
            return {}

        # Filtrar apenas campos v√°lidos do schema
        dados_validos = {}
        for campo, valor in dados.items():
            if campo in schema and valor is not None:
                dados_validos[campo] = valor

        return dados_validos

    def _calculate_adaptive_confidence(self, similar_docs: list) -> float:
        """Calcula confian√ßa adaptativa"""
        if not similar_docs:
            return 0.7

        # Baseado na similaridade dos documentos encontrados
        avg_similarity = sum(doc.get('similarity', 0.8)
                             for doc in similar_docs) / len(similar_docs)
        return min(0.95, avg_similarity + 0.1)

    def _calculate_extraction_confidence(self, similar_docs: list, dados_extraidos: Dict) -> float:
        """Calcula confian√ßa da extra√ß√£o"""
        base_confidence = 0.6

        if similar_docs:
            base_confidence += 0.2

        if dados_extraidos and len(dados_extraidos) > 0:
            base_confidence += 0.1

        return min(0.95, base_confidence)

    def _calcular_custos_totais(self, metadados_list: list) -> Dict[str, Any]:
        """Calcula custos totais"""
        custos = {"total_input_tokens": 0, "total_output_tokens": 0}

        for metadata in metadados_list:
            custos["total_input_tokens"] += metadata.get("input_tokens", 0)
            custos["total_output_tokens"] += metadata.get("output_tokens", 0)

        return custos

    async def _salvar_no_banco_vetorial(
        self, texto: str, tipo_documento: str, dados_extraidos: Dict,
        confianca: float, db_session: Optional[Session]
    ):
        """Salva documento no banco vetorial"""
        try:
            if self.vector_service:
                await self.vector_service.add_document(
                    text=texto,
                    document_type=tipo_documento,
                    extracted_data=dados_extraidos,
                    metadata={
                        "confidence": confianca,
                        "timestamp": time.time()
                    }
                )
        except Exception as e:
            logger.warning(f"Erro ao salvar no banco vetorial: {e}")

    async def _extract_from_chunk(self, chunk: str, document_type: str, schema_text: str) -> Dict:
        """Extrai dados de um chunk espec√≠fico"""
        try:
            result = self.extraction_base_chain.invoke({
                "document_type": document_type,
                "schema": schema_text,
                "document_text": chunk
            })
            return result if isinstance(result, dict) else {}
        except Exception as e:
            logger.error(f"Erro ao extrair de chunk: {e}")
            return {}

    def _consolidate_chunk_results(self, chunk_results: list, schema: Dict) -> Dict:
        """Consolida resultados de m√∫ltiplos chunks"""
        consolidated = {}

        for chunk, data in chunk_results:
            for field, value in data.items():
                if field in schema and value:
                    if field not in consolidated:
                        consolidated[field] = value
                    elif len(str(value)) > len(str(consolidated[field])):
                        # Manter o valor mais detalhado
                        consolidated[field] = value

        return consolidated

    def _calculate_chunked_confidence(self, chunk_results: list) -> float:
        """Calcula confian√ßa para resultados de chunks"""
        if not chunk_results:
            return 0.0

        successful_chunks = sum(1 for _, data in chunk_results if data)
        total_chunks = len(chunk_results)

        return min(0.9, successful_chunks / total_chunks * 0.8)
